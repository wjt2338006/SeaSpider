错误日志处理接入kafka   //已经写好，遇到错误接入即可
分析过程使用kafka来流化，考虑将下载器加入到客户解析的过程中 //ok
测试新过程是否和以前表现一样 //ok
优化与kafka相关的一些功能 //ok


日志记录要可以设计为查看，即有方法实时掌握日志
第一次进入页面时时间要有超时设置，web上要有专门的线程来负责处理日志，并聚合到产品下
对于解析错误的数据，单独推入另外一个频道等待人工处理，方便修正爬虫脚本，
    对于解析错误能够推送到相关产品，因为至少产品是有的，得到其错误，修正脚本后，尝试单条重跑
跟踪商品在不同的关键词下的排名，了解其关联关系，加一个字表
排名需要详细的位数，除开广告页外，应该精准算出当前位置


web
界面要限制条数
关键词查找

